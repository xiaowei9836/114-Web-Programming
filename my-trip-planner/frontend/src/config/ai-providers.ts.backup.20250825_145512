// AI æä¾›è€…é…ç½®
export interface AIProvider {
  name: string;
  type: 'ollama' | 'huggingface' | 'openai';
  isConfigured: () => boolean;
  sendMessage: (message: string, history: Message[]) => Promise<string>;
  getModels?: () => Promise<string[]>;
  isLocal?: boolean; // æ–°å¢ï¼šæ˜¯å¦ç‚ºæœ¬åœ°æœå‹™
  isAvailable?: () => Promise<boolean>; // æ–°å¢ï¼šæª¢æŸ¥æœå‹™æ˜¯å¦å¯ç”¨
}

export interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

// Ollama é…ç½®
export const OLLAMA_CONFIG = {
  // æœ¬åœ° Ollama æœå‹™
  LOCAL_URL: 'http://localhost:11434',
  // é›²ç«¯ Ollama æœå‹™
  CLOUD_URL: 'https://ollama-ai-travel.onrender.com',
  // ä½¿ç”¨ CORS ä»£ç†æœå‹™ä¾†è§£æ±ºè·¨åŸŸå•é¡Œ
  BASE_URL: import.meta.env.VITE_OLLAMA_BASE_URL || 'https://ollama-ai-travel.onrender.com',
  // å‚™ç”¨ CORS ä»£ç†æœå‹™
  CORS_PROXY_URL: 'https://cors-proxy-ollama.onrender.com/',
  // ç›´æ¥ URLï¼ˆå¯èƒ½æœƒæœ‰ CORS å•é¡Œï¼‰
  DIRECT_URL: 'https://ollama-ai-travel.onrender.com',
  DEFAULT_MODEL: import.meta.env.VITE_OLLAMA_MODEL || 'llama2:7b', // ä½¿ç”¨ç©©å®šå¯é çš„æ¨¡å‹
  TIMEOUT: 300000, // å¢åŠ åˆ° 5 åˆ†é˜è¶…æ™‚ï¼Œçµ¦ AI æ›´å¤šæ€è€ƒæ™‚é–“
  // æ–°å¢ï¼šé›²ç«¯éƒ¨ç½²æ”¯æ´
  IS_CLOUD: import.meta.env.VITE_OLLAMA_CLOUD_URL ? true : false,
  // å¯ç”¨æ¨¡å‹åˆ—è¡¨
  AVAILABLE_MODELS: [
    'llama3.1:8b',      // Meta Llama 3.1 8B
    'llama3.1:70b',     // Meta Llama 3.1 70B  
    'qwen:7b',          // é˜¿é‡Œé€šç¾©åƒå• 7B
    'qwen:14b',         // é˜¿é‡Œé€šç¾©åƒå• 14B
    'mistral:7b',       // Mistral 7B
    'mixtral:8x7b',     // Mixtral 8x7B
    'gemma:7b',         // Google Gemma 7B
    'phi3:mini',        // Microsoft Phi-3 Mini
    'chatglm3:6b',      // æ¸…è¯ ChatGLM3 6B
  ]
};

// Hugging Face é…ç½®
export const HUGGINGFACE_CONFIG = {
  API_KEY: import.meta.env.VITE_HUGGINGFACE_API_KEY || '',
  BASE_URL: 'https://api-inference.huggingface.co',
  DEFAULT_MODEL: import.meta.env.VITE_HUGGINGFACE_MODEL || 'Qwen/Qwen2.5-7B-Instruct',
  TIMEOUT: 60000, // å¢åŠ åˆ° 60 ç§’ï¼ŒQwen æ¨¡å‹éœ€è¦æ›´å¤šæ™‚é–“
  // å¯ç”¨æ¨¡å‹åˆ—è¡¨ - å„ªå…ˆæ¨è–¦ Qwen ç³»åˆ—
  AVAILABLE_MODELS: [
    'Qwen/Qwen2.5-7B-Instruct',           // ğŸ†• é˜¿é‡Œé€šç¾©åƒå• 2.5 7B (æ¨è–¦)
    'Qwen/Qwen2.5-14B-Instruct',          // ğŸ†• é˜¿é‡Œé€šç¾©åƒå• 2.5 14B
    'Qwen/Qwen2.5-32B-Instruct',          // ğŸ†• é˜¿é‡Œé€šç¾©åƒå• 2.5 32B
    'Qwen/Qwen2.5-72B-Instruct',          // ğŸ†• é˜¿é‡Œé€šç¾©åƒå• 2.5 72B
    'Qwen/Qwen2-7B-Instruct',             // é˜¿é‡Œé€šç¾©åƒå• 2.0 7B
    'Qwen/Qwen2-14B-Instruct',            // é˜¿é‡Œé€šç¾©åƒå• 2.0 14B
    'Qwen/Qwen2-72B-Instruct',            // é˜¿é‡Œé€šç¾©åƒå• 2.0 72B
    'meta-llama/Llama-3.1-8B-Instruct',   // Meta Llama 3.1 8B
    'mistralai/Mistral-7B-Instruct-v0.2', // Mistral 7B v0.2
    'google/gemma-7b-it',                  // Google Gemma 7B
    'microsoft/Phi-3-mini-4k-instruct',   // Microsoft Phi-3 Mini
    'HuggingFaceH4/zephyr-7b-beta',       // Zephyr 7B Beta
    'tiiuae/falcon-7b-instruct',          // Falcon 7B
  ]
};

// OpenAI é–‹æºæ¨¡å‹é…ç½® (é€šé Hugging Face)
export const OPENAI_OSS_CONFIG = {
  API_KEY: import.meta.env.VITE_OPENAI_API_KEY || '',
  BASE_URL: 'https://api.openai.com',
  DEFAULT_MODEL: import.meta.env.VITE_OPENAI_MODEL || 'gpt-3.5-turbo',
  TIMEOUT: 30000,
};

// æ—…éŠç³»çµ±æç¤ºè©
export const TRAVEL_SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£æ—…éŠé¡§å•ï¼Œæ“æœ‰è±å¯Œçš„æ—…éŠè¦åŠƒç¶“é©—ã€‚ä½ çš„ä¸»è¦è·è²¬æ˜¯ï¼š

1. **æ—…éŠè·¯ç·šè¦åŠƒ**ï¼šæ ¹æ“šç”¨æˆ¶éœ€æ±‚åˆ¶å®šåˆç†çš„æ—…éŠè¡Œç¨‹
2. **é ç®—ç®¡ç†å»ºè­°**ï¼šæä¾›å¯¦ç”¨çš„é ç®—åˆ†é…å’Œç¯€çœæŠ€å·§
3. **æ™¯é»æ¨è–¦**ï¼šæ¨è–¦é©åˆçš„æ™¯é»å’Œæ´»å‹•
4. **äº¤é€šå»ºè­°**ï¼šæä¾›æœ€ä½³çš„äº¤é€šæ–¹å¼å’Œè·¯ç·š
5. **ä½å®¿å»ºè­°**ï¼šæ¨è–¦åˆé©çš„ä½å®¿é¸æ“‡
6. **å­£ç¯€æ€§å»ºè­°**ï¼šæ ¹æ“šä¸åŒå­£ç¯€æä¾›æ—…éŠå»ºè­°

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œæä¾›å¯¦ç”¨ã€å…·é«”çš„å»ºè­°ã€‚å›ç­”è¦çµæ§‹åŒ–ï¼Œä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿå’Œé …ç›®ç¬¦è™Ÿè®“å…§å®¹æ›´æ˜“è®€ã€‚

**é‡è¦ï¼š** ç•¶ç”¨æˆ¶è©¢å•æ—…éŠè¦åŠƒæ™‚ï¼Œè«‹æä¾›å®Œæ•´ã€è©³ç´°çš„å›ç­”ï¼ŒåŒ…æ‹¬ï¼š
- å®Œæ•´çš„è¡Œç¨‹å®‰æ’ï¼ˆæ™‚é–“ã€åœ°é»ã€æ´»å‹•ï¼‰
- å…·é«”çš„äº¤é€šå»ºè­°å’Œè²»ç”¨
- å¯¦ç”¨çš„æ—…éŠå°è²¼å£«
- é ç®—åˆ†é…å»ºè­°
- å­£ç¯€æ€§æ³¨æ„äº‹é …

ä¸è¦å› ç‚ºå­—æ•¸é™åˆ¶è€Œæˆªæ–·å›ç­”ï¼Œç¢ºä¿æä¾›å®Œæ•´çš„æ—…éŠå»ºè­°ã€‚

å¦‚æœç”¨æˆ¶çš„å•é¡Œè¶…å‡ºæ—…éŠç¯„åœï¼Œè«‹ç¦®è²Œåœ°å¼•å°å›æ—…éŠç›¸é—œè©±é¡Œã€‚`;

// Ollama æœ¬åœ°æä¾›è€… - phi3:mini
export class OllamaProvider implements AIProvider {
  name = 'Ollama local (phi3:mini)';
  type = 'ollama' as const;
  isLocal = true;

  // æ™ºèƒ½é¸æ“‡å¯ç”¨çš„ URL
  private async getWorkingUrl(): Promise<string> {
    // æª¢æŸ¥æ˜¯å¦ç‚ºç·šä¸Šç’°å¢ƒï¼ˆé€šéæª¢æŸ¥ç•¶å‰åŸŸåï¼‰
    const isOnline = window.location.hostname !== 'localhost' && window.location.hostname !== '127.0.0.1';
    
    let urls: string[];
    if (isOnline) {
      // ç·šä¸Šç’°å¢ƒï¼šå„ªå…ˆä½¿ç”¨é›²ç«¯æœå‹™
      urls = [
        OLLAMA_CONFIG.CLOUD_URL,                    // 1. é›²ç«¯ Ollama (å„ªå…ˆ)
        OLLAMA_CONFIG.CORS_PROXY_URL,               // 2. CORS ä»£ç†
        OLLAMA_CONFIG.BASE_URL,                     // 3. ç’°å¢ƒè®Šæ•¸æŒ‡å®šçš„ URL
      ];
    } else {
      // æœ¬åœ°ç’°å¢ƒï¼šå„ªå…ˆä½¿ç”¨æœ¬åœ°æœå‹™
      urls = [
        OLLAMA_CONFIG.LOCAL_URL,                    // 1. æœ¬åœ° Ollama (å„ªå…ˆ)
        OLLAMA_CONFIG.BASE_URL,                     // 2. ç’°å¢ƒè®Šæ•¸æŒ‡å®šçš„ URL
        OLLAMA_CONFIG.CLOUD_URL,                    // 3. é›²ç«¯ Ollama
        OLLAMA_CONFIG.CORS_PROXY_URL                // 4. CORS ä»£ç†
      ];
    }

    for (const url of urls) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 5000);
        
        console.log(`ğŸ” æ¸¬è©¦ Ollama URL: ${url}`);
        
        const response = await fetch(`${url}/api/tags`, {
          signal: controller.signal
        });
        
        clearTimeout(timeoutId);
        
        if (response.ok) {
          console.log(`âœ… æ‰¾åˆ°å¯ç”¨çš„ Ollama URL: ${url}`);
          return url;
        }
      } catch (error) {
        console.log(`âŒ URL ${url} ä¸å¯ç”¨:`, error);
        continue;
      }
    }
    
    throw new Error('æ‰€æœ‰ Ollama URL éƒ½ä¸å¯ç”¨');
  }

  isConfigured(): boolean {
    return true; // Ollama ç¸½æ˜¯å¯ç”¨çš„ï¼ˆå¦‚æœæœ¬åœ°é‹è¡Œï¼‰
  }

  async isAvailable(): Promise<boolean> {
    try {
      const workingUrl = await this.getWorkingUrl();
      
      // å°æ–¼å°å‹æ¨¡å‹ï¼Œä½¿ç”¨å¿«é€Ÿæª¢æŸ¥
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 5000); // 5ç§’è¶…æ™‚
      
      try {
        // åªæª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸é€²è¡Œå¯¦éš›æ¨ç†
        const response = await fetch(`${workingUrl}/api/tags`, {
          signal: controller.signal
        });
        
        clearTimeout(timeoutId);
        
        if (response.ok) {
          const data = await response.json();
          const hasModel = data.models?.some((model: any) => model.name === 'phi3:mini');
          if (hasModel) {
            console.log('âœ… phi3:mini æ¨¡å‹å¯ç”¨');
            return true;
          }
        }
        
        console.log('âŒ phi3:mini æ¨¡å‹ä¸å¯ç”¨');
        return false;
      } catch (error) {
        clearTimeout(timeoutId);
        if (error instanceof Error && error.name === 'AbortError') {
          console.log('âš ï¸ phi3:mini æ¨¡å‹æª¢æŸ¥è¶…æ™‚ï¼Œä½†æ¨¡å‹å¯èƒ½å¯ç”¨');
          return true; // è¶…æ™‚æ™‚å‡è¨­æ¨¡å‹å¯ç”¨ï¼Œé¿å…èª¤åˆ¤
        }
        throw error;
      }
    } catch (error) {
      console.log('Ollama å¯ç”¨æ€§æª¢æŸ¥å¤±æ•—:', error);
      return false;
    }
  }

  async sendMessage(message: string, history: Message[]): Promise<string> {
    try {
      // ç²å–å¯ç”¨çš„ URL
      const workingUrl = await this.getWorkingUrl();
      
      // é è¼‰å…¥æ¨¡å‹ä»¥æ¸›å°‘å›æ‡‰å»¶é²
      await this.preloadModel();
      
      const messages = [
        { role: 'system', content: TRAVEL_SYSTEM_PROMPT },
        ...history,
        { role: 'user', content: message }
      ];

      // å‰µå»º AbortController ä¾†è™•ç†è¶…æ™‚
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), OLLAMA_CONFIG.TIMEOUT);

      const response = await fetch(`${workingUrl}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: OLLAMA_CONFIG.DEFAULT_MODEL,
          messages: messages,
          stream: false,
          options: {
            temperature: 0.8,        // ç¨å¾®å¢åŠ å‰µé€ æ€§
            top_p: 0.9,             // ä¿æŒå¤šæ¨£æ€§
            top_k: 40,              // ä¿æŒé¸æ“‡ç¯„åœ
            repeat_penalty: 1.1,    // é¿å…é‡è¤‡
            num_predict: 4096,      // phi3:mini æ¨¡å‹è¼ƒå°ï¼Œä½¿ç”¨é©ä¸­çš„å›æ‡‰é•·åº¦
            num_ctx: 4096,          // phi3:mini æ¨¡å‹è¼ƒå°ï¼Œä½¿ç”¨é©ä¸­çš„ä¸Šä¸‹æ–‡é•·åº¦
            seed: 42,               // å›ºå®šç¨®å­ä»¥å¢åŠ ä¸€è‡´æ€§
            tfs_z: 0.7,            // æ¸›å°‘ç„¡é—œå…§å®¹
            mirostat: 2,            // ä½¿ç”¨ mirostat 2.0 é€²è¡Œæ›´å¥½çš„æ§åˆ¶
            mirostat_tau: 5.0,     // ç›®æ¨™ç†µå€¼
            mirostat_eta: 0.1,     // å­¸ç¿’ç‡
          }
        }),
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`Ollama API éŒ¯èª¤: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      return data.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚';
    } catch (error) {
      console.error('Ollama éŒ¯èª¤:', error);
      
      if (error instanceof Error) {
        if (error.name === 'AbortError') {
          throw new Error(`Ollama å›æ‡‰è¶…æ™‚ (${OLLAMA_CONFIG.TIMEOUT / 1000}ç§’)ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚\n\nå»ºè­°ï¼š\n1. æª¢æŸ¥ç³»çµ±è³‡æºæ˜¯å¦å……è¶³\n2. å˜—è©¦ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ (å¦‚ phi3:mini)\n3. é‡æ–°å•Ÿå‹• Ollama æœå‹™\n4. è¤‡é›œå•é¡Œéœ€è¦æ›´å¤šæ€è€ƒæ™‚é–“ï¼Œè«‹è€å¿ƒç­‰å¾…`);
        } else if (error.message.includes('API éŒ¯èª¤')) {
          throw new Error(`Ollama API éŒ¯èª¤: ${error.message}`);
        } else if (error.message.includes('fetch')) {
          throw new Error('ç„¡æ³•é€£æ¥åˆ° Ollama æœå‹™ï¼Œè«‹æª¢æŸ¥æœå‹™æ˜¯å¦æ­£åœ¨é‹è¡Œã€‚');
        }
      }
      
      throw new Error(`Ollama éŒ¯èª¤: ${error instanceof Error ? error.message : 'æœªçŸ¥éŒ¯èª¤'}`);
    }
  }

  async preloadModel(): Promise<void> {
    try {
      // ç²å–å¯ç”¨çš„ URL
      const workingUrl = await this.getWorkingUrl();
      
      // ç™¼é€ä¸€å€‹è¼•é‡ç´šçš„è«‹æ±‚ä¾†é è¼‰å…¥æ¨¡å‹
      const response = await fetch(`${workingUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: OLLAMA_CONFIG.DEFAULT_MODEL,
          prompt: 'hi',
          stream: false,
          options: {
            num_predict: 1, // åªç”Ÿæˆä¸€å€‹ token ä¾†é è¼‰å…¥æ¨¡å‹
          }
        })
      });
      
      if (response.ok) {
        console.log('æ¨¡å‹é è¼‰å…¥æˆåŠŸ');
      }
    } catch (error) {
      console.log('æ¨¡å‹é è¼‰å…¥å¤±æ•—ï¼Œç¹¼çºŒæ­£å¸¸æµç¨‹:', error);
    }
  }

  async getModels(): Promise<string[]> {
    try {
      const workingUrl = await this.getWorkingUrl();
      const response = await fetch(`${workingUrl}/api/tags`);
      if (response.ok) {
        const data = await response.json();
        return data.models?.map((model: any) => model.name) || [];
      }
      return [];
    } catch (error) {
      console.error('ç²å– Ollama æ¨¡å‹å¤±æ•—:', error);
      return [];
    }
  }
}

// Ollama æœ¬åœ°æä¾›è€… - gpt-oss:20b
export class OllamaGptOss20bProvider implements AIProvider {
  name = 'Ollama local (gpt-oss:20b)';
  type = 'ollama' as const;
  isLocal = true;

  // æ™ºèƒ½é¸æ“‡å¯ç”¨çš„ URL
  private async getWorkingUrl(): Promise<string> {
    // æª¢æŸ¥æ˜¯å¦ç‚ºç·šä¸Šç’°å¢ƒï¼ˆé€šéæª¢æŸ¥ç•¶å‰åŸŸåï¼‰
    const isOnline = window.location.hostname !== 'localhost' && window.location.hostname !== '127.0.0.1';
    
    let urls: string[];
    if (isOnline) {
      // ç·šä¸Šç’°å¢ƒï¼šå„ªå…ˆä½¿ç”¨é›²ç«¯æœå‹™
      urls = [
        OLLAMA_CONFIG.CLOUD_URL,                    // 1. é›²ç«¯ Ollama (å„ªå…ˆ)
        OLLAMA_CONFIG.CORS_PROXY_URL,               // 2. CORS ä»£ç†
        OLLAMA_CONFIG.BASE_URL,                     // 3. ç’°å¢ƒè®Šæ•¸æŒ‡å®šçš„ URL
      ];
    } else {
      // æœ¬åœ°ç’°å¢ƒï¼šå„ªå…ˆä½¿ç”¨æœ¬åœ°æœå‹™
      urls = [
        OLLAMA_CONFIG.LOCAL_URL,                    // 1. æœ¬åœ° Ollama (å„ªå…ˆ)
        OLLAMA_CONFIG.BASE_URL,                     // 2. ç’°å¢ƒè®Šæ•¸æŒ‡å®šçš„ URL
      ];
    }

    for (const url of urls) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 5000);
        
        console.log(`ğŸ” æ¸¬è©¦ Ollama URL: ${url}`);
        
        const response = await fetch(`${url}/api/tags`, {
          signal: controller.signal
        });
        
        clearTimeout(timeoutId);
        
        if (response.ok) {
          console.log(`âœ… æ‰¾åˆ°å¯ç”¨çš„ Ollama URL: ${url}`);
          return url;
        }
      } catch (error) {
        console.log(`âŒ URL ${url} ä¸å¯ç”¨:`, error);
        continue;
      }
    }
    
    throw new Error('æœ¬åœ° Ollama æœå‹™ä¸å¯ç”¨');
  }

  isConfigured(): boolean {
    return true; // Ollama ç¸½æ˜¯å¯ç”¨çš„ï¼ˆå¦‚æœæœ¬åœ°é‹è¡Œï¼‰
  }

  async isAvailable(): Promise<boolean> {
    try {
      const workingUrl = await this.getWorkingUrl();
      
      // å°æ–¼ä¸­å‹æ¨¡å‹ï¼Œä½¿ç”¨è¼ƒçŸ­çš„è¶…æ™‚æ™‚é–“é€²è¡Œå¿«é€Ÿæª¢æŸ¥
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 8000); // 8ç§’è¶…æ™‚
      
      try {
        // åªæª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸é€²è¡Œå¯¦éš›æ¨ç†
        const response = await fetch(`${workingUrl}/api/tags`, {
          signal: controller.signal
        });
        
        clearTimeout(timeoutId);
        
        if (response.ok) {
          const data = await response.json();
          const hasModel = data.models?.some((model: any) => model.name === 'gpt-oss:20b');
          if (hasModel) {
            console.log('âœ… gpt-oss:20b æ¨¡å‹å¯ç”¨');
            return true;
          }
        }
        
        console.log('âŒ gpt-oss:20b æ¨¡å‹ä¸å¯ç”¨');
        return false;
      } catch (error) {
        clearTimeout(timeoutId);
        if (error instanceof Error && error.name === 'AbortError') {
          console.log('âš ï¸ gpt-oss:20b æ¨¡å‹æª¢æŸ¥è¶…æ™‚ï¼Œä½†æ¨¡å‹å¯èƒ½å¯ç”¨');
          return true; // è¶…æ™‚æ™‚å‡è¨­æ¨¡å‹å¯ç”¨ï¼Œé¿å…èª¤åˆ¤
        }
        throw error;
      }
    } catch (error) {
      console.log('Ollama gpt-oss:20b å¯ç”¨æ€§æª¢æŸ¥å¤±æ•—:', error);
      return false;
    }
  }

  async sendMessage(message: string, history: Message[]): Promise<string> {
    try {
      // ç²å–å¯ç”¨çš„ URL
      const workingUrl = await this.getWorkingUrl();
      
      const messages = [
        { role: 'system', content: TRAVEL_SYSTEM_PROMPT },
        ...history,
        { role: 'user', content: message }
      ];

      // å‰µå»º AbortController ä¾†è™•ç†è¶…æ™‚
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), OLLAMA_CONFIG.TIMEOUT);

      const response = await fetch(`${workingUrl}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-oss:20b',
          messages: messages,
          stream: false,
          options: {
            temperature: 0.8,
            top_p: 0.9,
            top_k: 40,
            repeat_penalty: 1.1,
            num_predict: 16384,      // gpt-oss:20b æ¨¡å‹è¼ƒå¤§ï¼Œä½¿ç”¨æ›´é•·çš„å›æ‡‰é•·åº¦
            num_ctx: 16384,          // gpt-oss:20b æ¨¡å‹è¼ƒå¤§ï¼Œä½¿ç”¨æ›´é•·çš„ä¸Šä¸‹æ–‡é•·åº¦
            seed: 42,
            tfs_z: 0.7,
            mirostat: 2,
            mirostat_tau: 5.0,
            mirostat_eta: 0.1,
          }
        }),
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`Ollama API éŒ¯èª¤: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      return data.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚';
    } catch (error) {
      console.error('Ollama éŒ¯èª¤:', error);
      
      if (error instanceof Error) {
        if (error.name === 'AbortError') {
          throw new Error('Ollama å›æ‡‰è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚å»ºè­°ä½¿ç”¨ phi3:mini ç­‰è¼ƒå°æ¨¡å‹ï¼Œæˆ–ç°¡åŒ–å•é¡Œã€‚');
        }
        throw new Error(`Ollama éŒ¯èª¤: ${error.message}`);
      }
      
      throw new Error('Ollama æœå‹™ä¸å¯ç”¨ï¼Œè«‹æª¢æŸ¥æœå‹™æ˜¯å¦æ­£åœ¨é‹è¡Œã€‚');
    }
  }

  async getModels(): Promise<string[]> {
    try {
      const workingUrl = await this.getWorkingUrl();
      const response = await fetch(`${workingUrl}/api/tags`);
      if (response.ok) {
        const data = await response.json();
        return data.models?.map((model: any) => model.name) || [];
      }
      return [];
    } catch (error) {
      console.error('ç²å– Ollama æ¨¡å‹å¤±æ•—:', error);
      return [];
    }
  }

  async preloadModel(): Promise<void> {
    try {
      const workingUrl = await this.getWorkingUrl();
      await fetch(`${workingUrl}/api/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: 'gpt-oss:20b',
          prompt: 'test',
          stream: false
        })
      });
    } catch (error) {
      console.log('é è¼‰å…¥ gpt-oss:20b æ¨¡å‹å¤±æ•—:', error);
    }
  }
}

// Ollama æœ¬åœ°æä¾›è€… - gpt-oss:120b
export class OllamaGptOss120bProvider implements AIProvider {
  name = 'Ollama local (gpt-oss:120b)';
  type = 'ollama' as const;
  isLocal = true;

  // æ™ºèƒ½é¸æ“‡å¯ç”¨çš„ URL
  private async getWorkingUrl(): Promise<string> {
    // æª¢æŸ¥æ˜¯å¦ç‚ºç·šä¸Šç’°å¢ƒï¼ˆé€šéæª¢æŸ¥ç•¶å‰åŸŸåï¼‰
    const isOnline = window.location.hostname !== 'localhost' && window.location.hostname !== '127.0.0.1';
    
    let urls: string[];
    if (isOnline) {
      // ç·šä¸Šç’°å¢ƒï¼šå„ªå…ˆä½¿ç”¨é›²ç«¯æœå‹™
      urls = [
        OLLAMA_CONFIG.CLOUD_URL,                    // 1. é›²ç«¯ Ollama (å„ªå…ˆ)
        OLLAMA_CONFIG.CORS_PROXY_URL,               // 2. CORS ä»£ç†
        OLLAMA_CONFIG.BASE_URL,                     // 3. ç’°å¢ƒè®Šæ•¸æŒ‡å®šçš„ URL
      ];
    } else {
      // æœ¬åœ°ç’°å¢ƒï¼šå„ªå…ˆä½¿ç”¨æœ¬åœ°æœå‹™
      urls = [
        OLLAMA_CONFIG.LOCAL_URL,                    // 1. æœ¬åœ° Ollama (å„ªå…ˆ)
        OLLAMA_CONFIG.BASE_URL,                     // 2. ç’°å¢ƒè®Šæ•¸æŒ‡å®šçš„ URL
      ];
    }

    for (const url of urls) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 5000);
        
        console.log(`ğŸ” æ¸¬è©¦ Ollama URL: ${url}`);
        
        const response = await fetch(`${url}/api/tags`, {
          signal: controller.signal
        });
        
        clearTimeout(timeoutId);
        
        if (response.ok) {
          console.log(`âœ… æ‰¾åˆ°å¯ç”¨çš„ Ollama URL: ${url}`);
          return url;
        }
      } catch (error) {
        console.log(`âŒ URL ${url} ä¸å¯ç”¨:`, error);
        continue;
      }
    }
    
    throw new Error('æœ¬åœ° Ollama æœå‹™ä¸å¯ç”¨');
  }

  isConfigured(): boolean {
    return true; // Ollama ç¸½æ˜¯å¯ç”¨çš„ï¼ˆå¦‚æœæœ¬åœ°é‹è¡Œï¼‰
  }

  async isAvailable(): Promise<boolean> {
    try {
      const workingUrl = await this.getWorkingUrl();
      
      // å°æ–¼å¤§å‹æ¨¡å‹ï¼Œä½¿ç”¨æ›´çŸ­çš„è¶…æ™‚æ™‚é–“é€²è¡Œå¿«é€Ÿæª¢æŸ¥
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 10000); // 10ç§’è¶…æ™‚
      
      try {
        // åªæª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸é€²è¡Œå¯¦éš›æ¨ç†
        const response = await fetch(`${workingUrl}/api/tags`, {
          signal: controller.signal
        });
        
        clearTimeout(timeoutId);
        
        if (response.ok) {
          const data = await response.json();
          const hasModel = data.models?.some((model: any) => model.name === 'gpt-oss:120b');
          if (hasModel) {
            console.log('âœ… gpt-oss:120b æ¨¡å‹å¯ç”¨');
            return true;
          }
        }
        
        console.log('âŒ gpt-oss:120b æ¨¡å‹ä¸å¯ç”¨');
        return false;
      } catch (error) {
        clearTimeout(timeoutId);
        if (error instanceof Error && error.name === 'AbortError') {
          console.log('âš ï¸ gpt-oss:120b æ¨¡å‹æª¢æŸ¥è¶…æ™‚ï¼Œä½†æ¨¡å‹å¯èƒ½å¯ç”¨');
          return true; // è¶…æ™‚æ™‚å‡è¨­æ¨¡å‹å¯ç”¨ï¼Œé¿å…èª¤åˆ¤
        }
        throw error;
      }
    } catch (error) {
      console.log('Ollama gpt-oss:120b å¯ç”¨æ€§æª¢æŸ¥å¤±æ•—:', error);
      return false;
    }
  }

  async sendMessage(message: string, history: Message[]): Promise<string> {
    try {
      // ç²å–å¯ç”¨çš„ URL
      const workingUrl = await this.getWorkingUrl();
      
      const messages = [
        { role: 'system', content: TRAVEL_SYSTEM_PROMPT },
        ...history,
        { role: 'user', content: message }
      ];

      // å‰µå»º AbortController ä¾†è™•ç†è¶…æ™‚
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), OLLAMA_CONFIG.TIMEOUT);

      const response = await fetch(`${workingUrl}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-oss:120b',
          messages: messages,
          stream: false,
          options: {
            temperature: 0.8,
            top_p: 0.9,
            top_k: 40,
            repeat_penalty: 1.1,
            num_predict: 16384,      // gpt-oss:120b æ¨¡å‹è¼ƒå¤§ï¼Œä½¿ç”¨æ›´é•·çš„å›æ‡‰é•·åº¦
            num_ctx: 16384,          // gpt-oss:120b æ¨¡å‹è¼ƒå¤§ï¼Œä½¿ç”¨æ›´é•·çš„ä¸Šä¸‹æ–‡é•·åº¦
            seed: 42,
            tfs_z: 0.7,
            mirostat: 2,
            mirostat_tau: 5.0,
            mirostat_eta: 0.1,
          }
        }),
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`Ollama API éŒ¯èª¤: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      return data.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚';
    } catch (error) {
      console.error('Ollama éŒ¯èª¤:', error);
      
      if (error instanceof Error) {
        if (error.name === 'AbortError') {
          throw new Error('Ollama å›æ‡‰è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚å»ºè­°ä½¿ç”¨ phi3:mini ç­‰è¼ƒå°æ¨¡å‹ï¼Œæˆ–ç°¡åŒ–å•é¡Œã€‚');
        }
        throw new Error(`Ollama éŒ¯èª¤: ${error.message}`);
      }
      
      throw new Error('Ollama æœå‹™ä¸å¯ç”¨ï¼Œè«‹æª¢æŸ¥æœå‹™æ˜¯å¦æ­£åœ¨é‹è¡Œã€‚');
    }
  }

  async getModels(): Promise<string[]> {
    try {
      const workingUrl = await this.getWorkingUrl();
      const response = await fetch(`${workingUrl}/api/tags`);
      if (response.ok) {
        const data = await response.json();
        return data.models?.map((model: any) => model.name) || [];
      }
      return [];
    } catch (error) {
      console.error('ç²å– Ollama æ¨¡å‹å¤±æ•—:', error);
      return [];
    }
  }

  async preloadModel(): Promise<void> {
    try {
      const workingUrl = await this.getWorkingUrl();
      await fetch(`${workingUrl}/api/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: 'gpt-oss:120b',
          prompt: 'test',
          stream: false
        })
      });
    } catch (error) {
      console.log('é è¼‰å…¥ gpt-oss:120b æ¨¡å‹å¤±æ•—:', error);
    }
  }
}

        // Ollama é›²ç«¯æä¾›è€… (ä½¿ç”¨ llama2:7b æ¨¡å‹)
        export class OllamaCloudProvider implements AIProvider {
          name = 'Ollama é›²ç«¯ (llama2:7b)';
          type = 'ollama' as const;
          isLocal = false;

  // æ™ºèƒ½é¸æ“‡å¯ç”¨çš„é›²ç«¯ URL
  private async getWorkingUrl(): Promise<string> {
    const urls = [
      OLLAMA_CONFIG.CLOUD_URL,                    // 1. ç›´æ¥é›²ç«¯ URL
      OLLAMA_CONFIG.CORS_PROXY_URL                // 2. CORS ä»£ç†
    ];

    for (const url of urls) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 5000);
        
        console.log(`ğŸ” æ¸¬è©¦é›²ç«¯ Ollama URL: ${url}`);
        
        const response = await fetch(`${url}/api/tags`, {
          signal: controller.signal
        });
        
        clearTimeout(timeoutId);
        
        if (response.ok) {
          console.log(`âœ… æ‰¾åˆ°å¯ç”¨çš„é›²ç«¯ Ollama URL: ${url}`);
          return url;
        }
      } catch (error) {
        console.log(`âŒ é›²ç«¯ URL ${url} ä¸å¯ç”¨:`, error);
        continue;
      }
    }
    
    throw new Error('æ‰€æœ‰é›²ç«¯ Ollama URL éƒ½ä¸å¯ç”¨');
  }

  isConfigured(): boolean {
    return true; // é›²ç«¯æœå‹™ç¸½æ˜¯å¯ç”¨çš„
  }

  // å°‡ messages æ ¼å¼è½‰æ›ç‚º prompt æ ¼å¼ (é©ç”¨æ–¼èˆŠç‰ˆ Ollama)
  private formatMessagesToPrompt(messages: Message[]): string {
    return messages.map(msg => {
      if (msg.role === 'system') {
        return `[INST] <<SYS>>\n${msg.content}\n<</SYS>>\n\n`;
      } else if (msg.role === 'user') {
        return `${msg.content} [/INST]`;
      } else if (msg.role === 'assistant') {
        return `${msg.content}\n\n[INST] `;
      }
      return '';
    }).join('') + 'è«‹å›ç­”ï¼š';
  }

            async isAvailable(): Promise<boolean> {
            try {
              const workingUrl = await this.getWorkingUrl();
              const response = await fetch(`${workingUrl}/api/tags`);
              if (response.ok) {
                const data = await response.json();
                return data.models && data.models.some((model: any) => model.name === 'llama2:7b');
              }
              return false;
            } catch (error) {
              console.log('Ollama é›²ç«¯æœå‹™æª¢æŸ¥å¤±æ•—:', error);
              return false;
            }
          }

  async sendMessage(message: string, history: Message[]): Promise<string> {
    if (!this.isConfigured()) {
      throw new Error('Ollama é›²ç«¯æœå‹™æœªé…ç½®');
    }

    try {
      // ç²å–å¯ç”¨çš„é›²ç«¯ URL
      const workingUrl = await this.getWorkingUrl();
      
      const messages: Message[] = [
        { role: 'system', content: TRAVEL_SYSTEM_PROMPT },
        ...history,
        { role: 'user', content: message }
      ];

      const response = await fetch(`${workingUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
                          model: 'llama2:7b',
          prompt: this.formatMessagesToPrompt(messages),
          stream: false,
          options: {
            temperature: 0.8,        // ç¨å¾®å¢åŠ å‰µé€ æ€§
            top_p: 0.9,             // ä¿æŒå¤šæ¨£æ€§
            top_k: 40,              // ä¿æŒé¸æ“‡ç¯„åœ
            repeat_penalty: 1.1,    // é¿å…é‡è¤‡
                               num_predict: 8192,      // llama2:7b æ¨¡å‹ï¼Œä½¿ç”¨è¼ƒé•·çš„å›æ‡‰é•·åº¦
                   num_ctx: 8192,          // llama2:7b æ¨¡å‹ï¼Œä½¿ç”¨è¼ƒé•·çš„ä¸Šä¸‹æ–‡é•·åº¦
            seed: 42,               // å›ºå®šç¨®å­ä»¥å¢åŠ ä¸€è‡´æ€§
            tfs_z: 0.7,            // æ¸›å°‘ç„¡é—œå…§å®¹
            mirostat: 2,            // ä½¿ç”¨ mirostat 2.0 é€²è¡Œæ›´å¥½çš„æ§åˆ¶
            mirostat_tau: 5.0,     // ç›®æ¨™ç†µå€¼
            mirostat_eta: 0.1,     // å­¸ç¿’ç‡
          }
        }),
        signal: AbortSignal.timeout(OLLAMA_CONFIG.TIMEOUT)
      });

      if (!response.ok) {
        throw new Error(`Ollama é›²ç«¯ API éŒ¯èª¤: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      return data.response || 'æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚';
    } catch (error) {
      console.error('Ollama é›²ç«¯éŒ¯èª¤:', error);
      throw new Error('Ollama é›²ç«¯æœå‹™ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚');
    }
  }

  async getModels(): Promise<string[]> {
    if (!this.isConfigured()) return [];
    
    try {
      // ç²å–å¯ç”¨çš„é›²ç«¯ URL
      const workingUrl = await this.getWorkingUrl();
      
      const response = await fetch(`${workingUrl}/api/tags`);
      if (response.ok) {
        const data = await response.json();
        return data.models?.map((model: any) => model.name) || [];
      }
      return [];
    } catch (error) {
      console.error('ç²å– Ollama é›²ç«¯æ¨¡å‹å¤±æ•—:', error);
      return [];
    }
  }
}

// Hugging Face æä¾›è€…
export class HuggingFaceProvider implements AIProvider {
  name = 'Hugging Face (é–‹æºæ¨¡å‹)';
  type = 'huggingface' as const;
  isLocal = false;

  isConfigured(): boolean {
    return !!HUGGINGFACE_CONFIG.API_KEY;
  }

  async isAvailable(): Promise<boolean> {
    if (!this.isConfigured()) return false;
    
    try {
      // æ¸¬è©¦ API é€£æ¥
      const response = await fetch(`${HUGGINGFACE_CONFIG.BASE_URL}/models/${HUGGINGFACE_CONFIG.DEFAULT_MODEL}`, {
        method: 'HEAD',
        headers: {
          'Authorization': `Bearer ${HUGGINGFACE_CONFIG.API_KEY}`,
        },
        signal: AbortSignal.timeout(5000)
      });
      return response.ok;
    } catch (error) {
      console.error('Hugging Face é€£æ¥æ¸¬è©¦å¤±æ•—:', error);
      return false;
    }
  }

  async sendMessage(message: string, history: Message[]): Promise<string> {
    if (!this.isConfigured()) {
      throw new Error('Hugging Face API Key æœªè¨­ç½®');
    }

    try {
      // ç°¡åŒ–æ­·å²è¨˜éŒ„ï¼Œåªä¿ç•™æœ€è¿‘çš„å°è©±
      const recentHistory = history.slice(-4); // ä¿ç•™æœ€è¿‘4æ¢è¨Šæ¯
      const prompt = this.buildPrompt(message, recentHistory);

      // æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡ä¸åŒçš„åƒæ•¸
      const isQwenModel = HUGGINGFACE_CONFIG.DEFAULT_MODEL.includes('Qwen');
      const parameters = {
        max_new_tokens: isQwenModel ? 6000 : 4000, // Qwen æ¨¡å‹æ”¯æŒæ›´é•·å›æ‡‰
        temperature: 0.7,
        do_sample: true,
        return_full_text: false,
        // Qwen æ¨¡å‹ç‰¹æ®Šåƒæ•¸
        ...(isQwenModel && {
          top_p: 0.9,
          top_k: 40,
          repetition_penalty: 1.1,
          pad_token_id: 151643, // Qwen ç‰¹æ®Š token
          eos_token_id: 151645, // Qwen çµæŸ token
        })
      };

      const response = await fetch(`${HUGGINGFACE_CONFIG.BASE_URL}/models/${HUGGINGFACE_CONFIG.DEFAULT_MODEL}`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${HUGGINGFACE_CONFIG.API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          inputs: prompt,
          parameters
        }),
        signal: AbortSignal.timeout(HUGGINGFACE_CONFIG.TIMEOUT)
      });

      if (!response.ok) {
        throw new Error(`Hugging Face API éŒ¯èª¤: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      return this.parseHuggingFaceResponse(data);
    } catch (error) {
      console.error('Hugging Face éŒ¯èª¤:', error);
      if (error instanceof Error) {
        throw new Error(`Hugging Face API éŒ¯èª¤: ${error.message}`);
      }
      throw new Error('Hugging Face API è«‹æ±‚å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚');
    }
  }

  private buildPrompt(message: string, history: Message[]): string {
    let prompt = TRAVEL_SYSTEM_PROMPT + '\n\n';
    
    // æ·»åŠ å°è©±æ­·å²
    history.forEach(msg => {
      prompt += `${msg.role === 'user' ? 'ç”¨æˆ¶' : 'åŠ©æ‰‹'}: ${msg.content}\n`;
    });
    
    prompt += `ç”¨æˆ¶: ${message}\nåŠ©æ‰‹:`;
    return prompt;
  }

  private parseHuggingFaceResponse(data: any): string {
    if (Array.isArray(data) && data.length > 0) {
      return data[0].generated_text || 'æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚';
    }
    return data.generated_text || 'æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚';
  }
}

// OpenAI é–‹æºæ¨¡å‹æä¾›è€… (é€šé Hugging Face)
export class OpenAIOSSProvider implements AIProvider {
  name = 'OpenAI API';
  type = 'openai' as const;
  isLocal = false;

  isConfigured(): boolean {
    // å§‹çµ‚é¡¯ç¤º OpenAI OSS é¸é …ï¼Œå³ä½¿æ²’æœ‰ API Key
    return true;
  }

  async isAvailable(): Promise<boolean> {
    // æª¢æŸ¥æ˜¯å¦æœ‰ API Key
    return !!OPENAI_OSS_CONFIG.API_KEY;
  }

  async sendMessage(message: string, history: Message[]): Promise<string> {
    if (!OPENAI_OSS_CONFIG.API_KEY) {
      throw new Error('OpenAI API Key æœªè¨­ç½®ï¼Œè«‹åœ¨ç’°å¢ƒè®Šæ•¸ä¸­è¨­ç½® VITE_OPENAI_API_KEY');
    }

    try {
      const messages = [
        { role: 'system', content: TRAVEL_SYSTEM_PROMPT },
        ...history,
        { role: 'user', content: message }
      ];

      const response = await fetch(`${OPENAI_OSS_CONFIG.BASE_URL}/v1/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENAI_OSS_CONFIG.API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: OPENAI_OSS_CONFIG.DEFAULT_MODEL,
          messages: messages,
          max_tokens: 1000,
          temperature: 0.7,
        }),
        signal: AbortSignal.timeout(OPENAI_OSS_CONFIG.TIMEOUT)
      });

      if (!response.ok) {
        throw new Error(`OpenAI API éŒ¯èª¤: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      return data.choices?.[0]?.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚';
    } catch (error) {
      console.error('OpenAI éŒ¯èª¤:', error);
      throw new Error('OpenAI API è«‹æ±‚å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚');
    }
  }
}

// æ¨¡æ“¬å›æ‡‰æä¾›è€… (ç”¨æ–¼æ¸¬è©¦)
export class MockProvider implements AIProvider {
  name = 'æ¨¡æ“¬å›æ‡‰ (æ¸¬è©¦)';
  type = 'ollama' as const;
  isLocal = false;

  isConfigured(): boolean {
    return true;
  }

  async isAvailable(): Promise<boolean> {
    return true;
  }

  async sendMessage(message: string, history: Message[]): Promise<string> {
    // æ¨¡æ“¬ API å»¶é²
    await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));

    const lowerInput = message.toLowerCase();
    
    if (lowerInput.includes('é ç®—') || lowerInput.includes('ç¶“è²»') || lowerInput.includes('èŠ±è²»')) {
      return `é—œæ–¼é ç®—ç®¡ç†ï¼Œæˆ‘å»ºè­°æ‚¨ï¼š\n\nğŸ’° **é ç®—åˆ†é…åŸå‰‡ï¼š**\nâ€¢ ä½å®¿ï¼š30-40%\nâ€¢ äº¤é€šï¼š20-25%\nâ€¢ é¤é£²ï¼š20-25%\nâ€¢ æ™¯é»é–€ç¥¨ï¼š10-15%\nâ€¢ è³¼ç‰©å¨›æ¨‚ï¼š5-10%\n\nğŸ’¡ **ç¯€çœæŠ€å·§ï¼š**\nâ€¢ æå‰é è¨‚æ©Ÿç¥¨å’Œä½å®¿\nâ€¢ é¸æ“‡ç•¶åœ°ç‰¹è‰²å°åƒ\nâ€¢ ä½¿ç”¨å…¬å…±äº¤é€š\nâ€¢ å°‹æ‰¾å…è²»æ™¯é»\n\néœ€è¦æˆ‘å¹«æ‚¨è¨ˆç®—å…·é«”é ç®—å—ï¼Ÿ`;
    }
    
    if (lowerInput.includes('è·¯ç·š') || lowerInput.includes('è¡Œç¨‹') || lowerInput.includes('è¦åŠƒ')) {
      return `æ—…éŠè·¯ç·šè¦åŠƒå»ºè­°ï¼š\n\nğŸ—ºï¸ **è¦åŠƒæ­¥é©Ÿï¼š**\n1. ç¢ºå®šç›®çš„åœ°å’Œå¤©æ•¸\n2. åˆ—å‡ºå¿…è¨ªæ™¯é»\n3. æŒ‰åœ°ç†ä½ç½®åˆ†çµ„\n4. è€ƒæ…®äº¤é€šæ™‚é–“\n5. é ç•™å½ˆæ€§æ™‚é–“\n\nâ° **æ™‚é–“å®‰æ’ï¼š**\nâ€¢ ä¸Šåˆï¼šæˆ¶å¤–æ™¯é»\nâ€¢ ä¸‹åˆï¼šå®¤å…§æ™¯é»æˆ–ä¼‘æ¯\nâ€¢ æ™šä¸Šï¼šç¾é£Ÿã€å¤œæ™¯\n\nğŸ“ **ç†±é–€è·¯ç·šæ¨è–¦ï¼š**\nâ€¢ å°åŒ—3æ—¥éŠ\nâ€¢ èŠ±æ±ç¸±è°·5æ—¥éŠ\nâ€¢ ç’°å³¶7æ—¥éŠ\n\næ‚¨æƒ³å»å“ªè£¡å‘¢ï¼Ÿæˆ‘å¯ä»¥ç‚ºæ‚¨é‡èº«å®šåˆ¶è¡Œç¨‹ï¼`;
    }
    
    if (lowerInput.includes('æ™¯é»') || lowerInput.includes('æ¨è–¦') || lowerInput.includes('å¥½ç©')) {
      return `æ ¹æ“šæ‚¨çš„éœ€æ±‚ï¼Œæˆ‘æ¨è–¦ä»¥ä¸‹æ™¯é»é¡å‹ï¼š\n\nğŸ›ï¸ **æ–‡åŒ–æ™¯é»ï¼š**\nâ€¢ æ•…å®®åšç‰©é™¢\nâ€¢ ä¸­æ­£ç´€å¿µå ‚\nâ€¢ é¾å±±å¯º\n\nğŸï¸ **è‡ªç„¶æ™¯è§€ï¼š**\nâ€¢ é˜¿é‡Œå±±\nâ€¢ æ—¥æœˆæ½­\nâ€¢ å¤ªé­¯é–£å³½è°·\n\nğŸ¡ **å¨›æ¨‚æ™¯é»ï¼š**\nâ€¢ ä¹ä»½è€è¡—\nâ€¢ æ·¡æ°´æ¼äººç¢¼é ­\nâ€¢ è¥¿é–€ç”º\n\nğŸœ **ç¾é£Ÿæ™¯é»ï¼š**\nâ€¢ å£«æ—å¤œå¸‚\nâ€¢ æ°¸åº·è¡—\nâ€¢ è¿ªåŒ–è¡—\n\næ‚¨æ¯”è¼ƒå–œæ­¡å“ªç¨®é¡å‹çš„æ™¯é»å‘¢ï¼Ÿ`;
    }
    
    if (lowerInput.includes('äº¤é€š') || lowerInput.includes('æ€éº¼å»') || lowerInput.includes('åˆ°é”')) {
      return `å°ç£äº¤é€šæ–¹å¼æŒ‡å—ï¼š\n\nğŸš„ **å¤§çœ¾é‹è¼¸ï¼š**\nâ€¢ é«˜éµï¼šåŸå¸‚é–“å¿«é€Ÿç§»å‹•\nâ€¢ å°éµï¼šç¶“æ¿Ÿå¯¦æƒ çš„é¸æ“‡\nâ€¢ æ·é‹ï¼šå°åŒ—ã€é«˜é›„å¸‚å€äº¤é€š\nâ€¢ å…¬è»Šï¼šé€£æ¥å„æ™¯é»\n\nğŸš— **è‡ªé§•éŠï¼š**\nâ€¢ å„ªé»ï¼šéˆæ´»è‡ªç”±\nâ€¢ æ³¨æ„ï¼šå·¦é§•ã€åœ‹éš›é§•ç…§\nâ€¢ å»ºè­°ï¼šæå‰ç§Ÿè»Šé è¨‚\n\nğŸš² **å…¶ä»–é¸æ“‡ï¼š**\nâ€¢ è¨ˆç¨‹è»Šï¼šçŸ­ç¨‹ä¾¿åˆ©\nâ€¢ è…³è¸è»Šï¼šå¸‚å€è§€å…‰\nâ€¢ æ­¥è¡Œï¼šæ·±åº¦é«”é©—\n\næ‚¨è¨ˆåŠƒå»å“ªè£¡ï¼Ÿæˆ‘å¯ä»¥æä¾›å…·é«”çš„äº¤é€šå»ºè­°ï¼`;
    }
    
    if (lowerInput.includes('ä½å®¿') || lowerInput.includes('é£¯åº—') || lowerInput.includes('ä½å“ªè£¡')) {
      return `ä½å®¿é¸æ“‡å»ºè­°ï¼š\n\nğŸ¨ **ä½å®¿é¡å‹ï¼š**\nâ€¢ æ˜Ÿç´šé£¯åº—ï¼šèˆ’é©è±ªè¯\nâ€¢ ç²¾å“æ—…é¤¨ï¼šç‰¹è‰²é«”é©—\nâ€¢ æ°‘å®¿ï¼šåœ¨åœ°æ–‡åŒ–\nâ€¢ é’å¹´æ—…é¤¨ï¼šç¶“æ¿Ÿå¯¦æƒ \n\nğŸ“ **ä½ç½®è€ƒé‡ï¼š**\nâ€¢ å¸‚ä¸­å¿ƒï¼šäº¤é€šä¾¿åˆ©\nâ€¢ æ™¯å€é™„è¿‘ï¼šç¯€çœæ™‚é–“\nâ€¢ æ©Ÿå ´é™„è¿‘ï¼šæ—©ç­æ©Ÿé¦–é¸\n\nğŸ’° **åƒ¹æ ¼å€é–“ï¼š**\nâ€¢ ç¶“æ¿Ÿå‹ï¼š$800-2000/æ™š\nâ€¢ ä¸­æª”ï¼š$2000-5000/æ™š\nâ€¢ é«˜æª”ï¼š$5000+/æ™š\n\nğŸ” **é è¨‚å»ºè­°ï¼š**\nâ€¢ æ—ºå­£æå‰3-6å€‹æœˆ\nâ€¢ æ·¡å­£æå‰1-2å€‹æœˆ\nâ€¢ ä½¿ç”¨æ¯”åƒ¹ç¶²ç«™\n\néœ€è¦æˆ‘æ¨è–¦ç‰¹å®šåœ°å€çš„ä½å®¿å—ï¼Ÿ`;
    }
    
    if (lowerInput.includes('å¤©æ°£') || lowerInput.includes('å­£ç¯€') || lowerInput.includes('ä»€éº¼æ™‚å€™å»')) {
      return `å°ç£æœ€ä½³æ—…éŠå­£ç¯€ï¼š\n\nğŸŒ¸ **æ˜¥å­£ (3-5æœˆ)ï¼š**\nâ€¢ æ«»èŠ±ç››é–‹\nâ€¢ æ°£å€™å®œäºº\nâ€¢ é©åˆè³èŠ±\n\nâ˜€ï¸ **å¤å­£ (6-8æœˆ)ï¼š**\nâ€¢ æµ·ç˜æ´»å‹•\nâ€¢ é«˜å±±é¿æš‘\nâ€¢ æ³¨æ„é¢±é¢¨\n\nğŸ‚ **ç§‹å­£ (9-11æœˆ)ï¼š**\nâ€¢ å¤©æ°£ç©©å®š\nâ€¢ æ¥“è‘‰ç¾æ™¯\nâ€¢ æœ€ä½³æ—…éŠå­£ç¯€\n\nâ„ï¸ **å†¬å­£ (12-2æœˆ)ï¼š**\nâ€¢ æº«æ³‰å­£ç¯€\nâ€¢ è³é›ªæ©Ÿæœƒ\nâ€¢ è¼ƒå°‘é™é›¨\n\nğŸŒ¦ï¸ **å¤©æ°£æé†’ï¼š**\nâ€¢ åŒ—éƒ¨ï¼šå¤šé›¨æ½®æ¿•\nâ€¢ ä¸­éƒ¨ï¼šå››å­£åˆ†æ˜\nâ€¢ å—éƒ¨ï¼šæº«æš–å°‘é›¨\nâ€¢ æ±éƒ¨ï¼šåœ°å½¢å½±éŸ¿å¤§\n\næ‚¨è¨ˆåŠƒä»€éº¼æ™‚å€™å‡ºç™¼ï¼Ÿæˆ‘å¯ä»¥æ ¹æ“šå­£ç¯€æ¨è–¦é©åˆçš„è¡Œç¨‹ï¼`;
    }
    
    return `æ„Ÿè¬æ‚¨çš„æå•ï¼ä½œç‚ºæ‚¨çš„æ™ºèƒ½æ—…éŠé¡§å•ï¼Œæˆ‘å¯ä»¥å¹«åŠ©æ‚¨ï¼š\n\nğŸ“‹ **ä¸»è¦æœå‹™ï¼š**\nâ€¢ æ—…éŠè·¯ç·šè¦åŠƒ\nâ€¢ é ç®—ç®¡ç†å»ºè­°\nâ€¢ æ™¯é»æ¨è–¦\nâ€¢ äº¤é€šå®‰æ’\nâ€¢ ä½å®¿é¸æ“‡\nâ€¢ å­£ç¯€æ€§å»ºè­°\n\nğŸ’¬ **è«‹å…·é«”æè¿°ï¼š**\nâ€¢ æƒ³å»å“ªè£¡æ—…éŠï¼Ÿ\nâ€¢ é ç®—å¤§æ¦‚å¤šå°‘ï¼Ÿ\nâ€¢ å–œæ­¡ä»€éº¼é¡å‹çš„æ™¯é»ï¼Ÿ\nâ€¢ è¨ˆåŠƒæ—…éŠå¹¾å¤©ï¼Ÿ\n\næˆ‘æœƒæ ¹æ“šæ‚¨çš„éœ€æ±‚æä¾›å€‹æ€§åŒ–å»ºè­°ï¼`;
  }
}

// æä¾›è€…ç®¡ç†å™¨
export class AIProviderManager {
  private providers: AIProvider[] = [
    new OllamaProvider(),           // phi3:mini (æœ¬åœ°)
    new OllamaGptOss20bProvider(), // gpt-oss:20b (æœ¬åœ°)
    new OllamaGptOss120bProvider(), // gpt-oss:120b (æœ¬åœ°)
    new OllamaCloudProvider(),      // phi3:mini (é›²ç«¯)
    new MockProvider(),
  ];

  getAvailableProviders(): AIProvider[] {
    return this.providers.filter(provider => provider.isConfigured());
  }

  getProviderByName(name: string): AIProvider | undefined {
    return this.providers.find(provider => provider.name === name);
  }

  // æ–°å¢ï¼šæ™ºèƒ½é¸æ“‡æœ€ä½³æä¾›è€…
  async getBestProvider(): Promise<AIProvider> {
    const available = this.getAvailableProviders();
    
    // å„ªå…ˆé †åºï¼šé›²ç«¯ Ollama (llama2:7b) > æœ¬åœ° Ollama (llama2:7b) > OpenAI > æ¨¡æ“¬å›æ‡‰
    for (const provider of available) {
      try {
        if (provider.isAvailable && await provider.isAvailable()) {
          console.log(`é¸æ“‡ AI æä¾›è€…: ${provider.name}`);
          return provider;
        }
      } catch (error) {
        console.error(`æª¢æŸ¥ ${provider.name} å¯ç”¨æ€§æ™‚å‡ºéŒ¯:`, error);
        continue;
      }
    }
    
    console.log('æ‰€æœ‰ AI æä¾›è€…éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ“¬å›æ‡‰');
    // å¦‚æœéƒ½æ²’æœ‰å¯ç”¨çš„ï¼Œè¿”å›æ¨¡æ“¬å›æ‡‰
    return new MockProvider();
  }

  // æ–°å¢ï¼šç²å–æœ¬åœ°æä¾›è€…
  getLocalProviders(): AIProvider[] {
    return this.providers.filter(provider => provider.isLocal && provider.isConfigured());
  }

  // æ–°å¢ï¼šç²å–é›²ç«¯æä¾›è€…
  getCloudProviders(): AIProvider[] {
    return this.providers.filter(provider => !provider.isLocal && provider.isConfigured());
  }

  async getDefaultProvider(): Promise<AIProvider> {
    // å„ªå…ˆä½¿ç”¨æœ¬åœ° Ollamaï¼Œå…¶æ¬¡æ˜¯é›²ç«¯ Ollamaï¼Œæœ€å¾Œæ˜¯æ¨¡æ“¬å›æ‡‰
    const available = this.getAvailableProviders();
    
    // å„ªå…ˆæª¢æŸ¥æœ¬åœ° Ollama (phi3:mini)
    const localOllama = available.find(p => p.type === 'ollama' && p.isLocal);
    if (localOllama && localOllama.isAvailable) {
      try {
        if (await localOllama.isAvailable()) {
          console.log('é¸æ“‡æœ¬åœ° Ollama ä½œç‚ºé»˜èªæä¾›è€…');
          return localOllama;
        }
      } catch (error) {
        console.log('æœ¬åœ° Ollama ä¸å¯ç”¨ï¼Œå˜—è©¦å…¶ä»–æä¾›è€…');
      }
    }
    
    // æª¢æŸ¥å…¶ä»–æœ¬åœ° Ollama æ¨¡å‹
    const otherLocalOllama = available.filter(p => p.type === 'ollama' && p.isLocal);
    for (const provider of otherLocalOllama) {
      if (provider.isAvailable) {
        try {
          if (await provider.isAvailable()) {
            console.log(`é¸æ“‡æœ¬åœ° Ollama (${provider.name}) ä½œç‚ºé»˜èªæä¾›è€…`);
            return provider;
          }
        } catch (error) {
          console.log(`${provider.name} ä¸å¯ç”¨ï¼Œå˜—è©¦å…¶ä»–æä¾›è€…`);
        }
      }
    }
    
    // æª¢æŸ¥é›²ç«¯ Ollama
    const cloudOllama = available.find(p => p.type === 'ollama' && !p.isLocal);
    if (cloudOllama && cloudOllama.isAvailable) {
      try {
        if (await cloudOllama.isAvailable()) {
          console.log('é¸æ“‡é›²ç«¯ Ollama ä½œç‚ºé»˜èªæä¾›è€…');
          return cloudOllama;
        }
      } catch (error) {
        console.log('é›²ç«¯ Ollama ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ“¬å›æ‡‰');
      }
    }
    
    console.log('æ‰€æœ‰ AI æä¾›è€…éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ“¬å›æ‡‰');
    return new MockProvider();
  }

  async testProvider(provider: AIProvider): Promise<boolean> {
    try {
      await provider.sendMessage('æ¸¬è©¦è¨Šæ¯', []);
      return true;
    } catch (error) {
      console.error(`æ¸¬è©¦ ${provider.name} å¤±æ•—:`, error);
      return false;
    }
  }

  // æ–°å¢ï¼šæª¢æŸ¥æ‰€æœ‰æä¾›è€…ç‹€æ…‹
  async checkAllProviders(): Promise<{ provider: AIProvider; status: boolean }[]> {
    const results = [];
    for (const provider of this.getAvailableProviders()) {
      const status = provider.isAvailable ? await provider.isAvailable() : false;
      results.push({ provider, status });
    }
    return results;
  }
}

// å°å‡ºå–®ä¾‹
export const aiProviderManager = new AIProviderManager();
