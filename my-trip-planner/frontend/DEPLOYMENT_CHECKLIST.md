# ✅ Ollama 線上部署檢查清單

## 🚀 **部署前準備**

### **本地環境檢查**
- [ ] Docker 已安裝並運行
- [ ] Git 已配置並可推送代碼
- [ ] Ollama 本地模型可用 (`gpt-oss:20b`, `gpt-oss:120b`)
- [ ] 前端項目可正常構建 (`npm run build`)

### **文件準備**
- [ ] `Dockerfile` 已創建
- [ ] `render.yaml` 已配置
- [ ] `.dockerignore` 已設置
- [ ] 部署腳本已準備 (`deploy-ollama-online.sh`)
- [ ] 前端配置更新腳本已準備 (`update-frontend-config.sh`)

## 🌐 **部署步驟**

### **步驟 1: 本地測試**
- [ ] 運行 `./deploy-ollama-online.sh` 進行本地測試
- [ ] 確認 Docker 鏡像構建成功
- [ ] 確認本地 Docker 容器運行正常
- [ ] 確認 API 測試通過
- [ ] 確認模型回應測試通過

### **步驟 2: 部署到 Render**
- [ ] 前往 [Render Dashboard](https://dashboard.render.com/)
- [ ] 連接 GitHub 倉庫
- [ ] 創建新的 Web Service
- [ ] 選擇 Docker 環境
- [ ] 配置服務名稱 (例如: `ollama-ai-travel`)
- [ ] 設置環境變數:
  - `OLLAMA_HOST=0.0.0.0`
  - `OLLAMA_MODELS=gpt-oss:20b,gpt-oss:120b`
- [ ] 設置健康檢查路徑: `/api/tags`
- [ ] 啟用自動部署
- [ ] 點擊 "Create Web Service"

### **步驟 3: 等待部署完成**
- [ ] 監控部署進度
- [ ] 確認服務狀態為 "Live"
- [ ] 記錄服務 URL (例如: `https://ollama-ai-travel.onrender.com`)

### **步驟 4: 測試線上服務**
- [ ] 健康檢查: `curl https://your-service.onrender.com/api/tags`
- [ ] 模型列表檢查: 確認模型可用
- [ ] 簡單回應測試: 測試基本 AI 功能
- [ ] 旅遊顧問測試: 測試旅遊問題回應

## 🔧 **前端配置更新**

### **步驟 5: 更新環境變數**
- [ ] 運行 `./update-frontend-config.sh`
- [ ] 輸入線上服務 URL
- [ ] 確認 `.env` 文件已更新
- [ ] 確認 `ai-providers.ts` 已更新
- [ ] 確認項目可正常構建

### **步驟 6: 推送代碼**
- [ ] 提交所有更改到 Git
- [ ] 推送到 GitHub 主分支
- [ ] 確認 Render 自動部署觸發

## 🧪 **部署後測試**

### **步驟 7: 功能驗證**
- [ ] 前端應用正常加載
- [ ] AI 旅遊顧問聊天窗口可打開
- [ ] 可發送旅遊相關問題
- [ ] AI 回應正常且內容相關
- [ ] 跨頁面對話持久性正常
- [ ] 聊天窗口功能正常 (最小化、最大化等)

### **步驟 8: 性能測試**
- [ ] 首次回應時間 (預期: 1-2 分鐘，免費計劃冷啟動)
- [ ] 後續回應時間 (預期: 10-30 秒)
- [ ] 模型切換功能正常
- [ ] 錯誤處理正常

## 📊 **監控和維護**

### **步驟 9: 設置監控**
- [ ] 監控服務狀態
- [ ] 監控回應時間
- [ ] 監控錯誤率
- [ ] 設置告警通知

### **步驟 10: 優化建議**
- [ ] 考慮升級到付費計劃以減少冷啟動延遲
- [ ] 根據使用情況調整模型大小
- [ ] 設置速率限制防止濫用
- [ ] 定期更新模型和依賴

## 🆘 **故障排除**

### **常見問題檢查**
- [ ] 服務無法啟動: 檢查 Docker 配置和資源限制
- [ ] 模型下載失敗: 檢查網路連接和模型名稱
- [ ] 回應超時: 檢查超時設置和模型大小
- [ ] 前端無法連接: 檢查 CORS 設置和 URL 配置

### **調試命令**
```bash
# 檢查服務狀態
docker logs <container_id>

# 檢查模型狀態
curl https://your-service.onrender.com/api/tags

# 檢查系統資源
docker stats <container_id>

# 測試 API 回應
curl -X POST https://your-service.onrender.com/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model":"gpt-oss:20b","prompt":"測試","stream":false}'
```

## 🎯 **成功標準**

### **功能完整性**
- [ ] AI 旅遊顧問可正常回應旅遊問題
- [ ] 回應內容包含實用的旅遊建議
- [ ] 聊天界面功能完整
- [ ] 跨頁面持久性正常

### **性能指標**
- [ ] 服務可用性 > 95%
- [ ] 平均回應時間 < 60 秒
- [ ] 錯誤率 < 5%
- [ ] 用戶體驗流暢

### **部署成功**
- [ ] 線上服務穩定運行
- [ ] 前端應用正常使用
- [ ] 其他使用者可正常訪問
- [ ] AI 功能完全可用

---

## 🎉 **部署完成檢查**

當所有項目都勾選完成後，您的 Ollama AI 旅遊顧問就成功部署到線上了！

**恭喜！🎊 現在其他使用者都可以使用您的 AI 旅遊顧問功能了！**

### **下一步建議**
1. **分享您的應用**: 讓朋友和同事測試
2. **收集反饋**: 根據用戶反饋優化功能
3. **監控使用情況**: 了解使用模式和性能
4. **持續改進**: 根據需求添加新功能

---

**準備好開始部署了嗎？讓我們將您的 AI 旅遊顧問帶到線上！** 🚀
